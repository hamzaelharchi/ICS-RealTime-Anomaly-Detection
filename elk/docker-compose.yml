version: '3.2'

services:
  zookeeper:
      image: confluentinc/cp-zookeeper:latest
      ports: 
        - "2181:2181"
      environment: 
        ZOOKEEPER_CLIENT_PORT: 2181
        ZOOKEEPER_TICK_TIME: 2000
      networks: 
        - elk
  kafka:
    image: confluentinc/cp-kafka:latest
    ports:
      - "9092:9092"
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    depends_on: 
      - zookeeper
    restart: on-failure
    networks: 
      - elk

  kafka_manager:
    image: hlebalbau/kafka-manager:stable
    ports:
      - "9000:9000"
    environment:
      ZK_HOSTS: "zookeeper:2181"
      APPLICATION_SECRET: "random-secret"
    networks:
      - elk


  elasticsearch:
    image: elasticsearch:7.9.0
      
    volumes:
      - type: bind
        source: ./elasticsearch/config/elasticsearch.yml
        target: /usr/share/elasticsearch/config/elasticsearch.yml
        read_only: true
      
    ports:
      - "9200:9200"
      - "9300:9300"
    environment:
     # ES_JAVA_OPTS: "-Xmx256m -Xms256m"
     # ELASTIC_PASSWORD: changeme
      discovery.type: single-node
    networks:
      - elk
  kibana:
    image: kibana:7.9.0
      
    volumes:
      - type: bind
        source: ./kibana/config/kibana.yml
        target: /usr/share/kibana/config/kibana.yml
        read_only: true
    ports:
      - "5601:5601"
    networks:
      - elk
    

  logstash:
    image: logstash:7.9.0

    volumes: 
     
      - type: bind
        source: ./logstash/pipeline/
        target: /usr/share/logstash/pipeline
      
       
    command: logstash -f /usr/share/logstash/pipeline/logstash.conf
    depends_on:
      - elasticsearch
    ports:
      - "5000:5000"
      - "9600:9600"
    networks:
      - elk



  pyspark:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: pyspark
    hostname: pyspark
    volumes:
      - ./notebooks:/home/jovyan/work
    ports:
      - "8888:8888"
    depends_on:
      - kafka
    #command: start-notebook.sh --NotebookApp.token='
    networks:
      - elk


  telegraf:
    image: telegraf
    container_name: telegraf
    restart: always
    volumes:
    - ./influxGrafana/telegraf.conf:/etc/telegraf/telegraf.conf:ro
    depends_on:
      - influxdb
    # links:
    #   - influxdb
    ports:
    - '8125:8125'
    networks:
      - elk


  influxdb:
    image: influxdb:1.8-alpine
    container_name: influxdb
    restart: always
    environment:
      - INFLUXDB_DB=influx
      - INFLUXDB_ADMIN_USER=admin
      - INFLUXDB_ADMIN_PASSWORD=admin 
    ports:
      - '8086:8086'
    volumes:
      - influxdb_data:/var/lib/influxdb
    networks:
      - elk

  grafana:
    image: grafana/grafana
    container_name: grafana-server
    restart: always
    depends_on:
      - influxdb
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_INSTALL_PLUGINS=
    # links:
    #   - influxdb
    ports:
      - '3000:3000'
    volumes:
      - grafana_data:/var/lib/grafana
    networks:
      - elk  
      
volumes:
  grafana_data: {}
  influxdb_data: {}

  
networks:
  elk:
    driver: bridge

      





   

    

      
  